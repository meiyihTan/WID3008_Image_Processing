{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import face_alignment\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from masked_face_sdk.utils import end2end_mask_generation\n",
    "from masked_face_sdk.pipeline_dataset_loader import PipelineFacesDatasetGenerator\n",
    "\n",
    "from masked_face_sdk.pipeline_dataset_loader \\\n",
    "    import PipelineFacesDatasetGenerator\n",
    "from masked_face_sdk.neural_network_modules \\\n",
    "    import Backbone, ArcFaceLayer, FaceRecognitionModel, resnet18\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11%|████▋                                     | 27/244 [00:52<07:43,  2.14s/it]Warning: No faces were detected.\n",
      " 25%|██████████▌                               | 61/244 [01:37<04:45,  1.56s/it]Warning: No faces were detected.\n",
      " 46%|██████████████████▊                      | 112/244 [02:40<03:55,  1.78s/it]Warning: No faces were detected.\n",
      " 50%|████████████████████▎                    | 121/244 [02:53<03:51,  1.88s/it]Warning: No faces were detected.\n",
      " 57%|███████████████████████▏                 | 138/244 [03:17<03:21,  1.90s/it]Warning: No faces were detected.\n",
      " 72%|█████████████████████████████▌           | 176/244 [04:26<05:30,  4.86s/it]Warning: No faces were detected.\n",
      " 78%|████████████████████████████████         | 191/244 [04:55<02:20,  2.65s/it]Warning: No faces were detected.\n",
      " 80%|████████████████████████████████▌        | 194/244 [04:59<01:25,  1.72s/it]Warning: No faces were detected.\n",
      " 81%|█████████████████████████████████▎       | 198/244 [05:06<01:20,  1.76s/it]Warning: No faces were detected.\n",
      "100%|█████████████████████████████████████████| 244/244 [06:09<00:00,  1.51s/it]\n",
      "Masks database successfully saved by follow path: data/masks_base.json\n"
     ]
    }
   ],
   "source": [
    "# Generate masks database\n",
    "!python3 generate_masks_database.py \\\n",
    "    --masks-folder=data/masked_faces/ \\\n",
    "    --database-file=data/masks_base.json \\\n",
    "    --verbose --skip-warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/101 [00:00<?, ?it/s]Warning: No faces were detected.\n",
      "Skipping and delete from base follow image: /media/alexey/DataDisk/datasets/vggface2_with_face_boxes_markup/test/n000001/0301_01.jpg, because can't find faces landmarks\n",
      " 41%|█████████████████                         | 41/101 [31:45<38:48, 38.81s/it]Skipping and delete from base follow image: Given input size: (512x1x1). Calculated output size: (512x0x0). Output size is too small, because unexpected error: /media/alexey/DataDisk/datasets/vggface2_with_face_boxes_markup/test/n000998/0230_03.jpg\n",
      " 56%|███████████████████████▋                  | 57/101 [41:55<35:26, 48.32s/it]Warning: No faces were detected.\n",
      "Skipping and delete from base follow image: /media/alexey/DataDisk/datasets/vggface2_with_face_boxes_markup/test/n001291/0445_01.jpg, because can't find faces landmarks\n",
      "100%|███████████████████████████████████████| 101/101 [1:05:58<00:00, 39.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Prepare training dataset\n",
    "root_train_dataset_path = '/media/alexey/DataDisk/datasets/vggface2_with_face_boxes_markup/test_large/'\n",
    "\n",
    "!python3 apply_masks_to_face_recognition_dataset.py \\\n",
    "    --face-dataset-folder={root_train_dataset_path} \\\n",
    "    --masks-database=data/masks_base.json \\\n",
    "    --verbose \\\n",
    "    --use-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset\n",
    "root_test_dataset_path = '/media/alexey/DataDisk/datasets/vggface2_with_face_boxes_markup/test_small/'\n",
    "\n",
    "!python3 apply_masks_to_face_recognition_dataset.py \\\n",
    "    --face-dataset-folder={root_test_dataset_path} \\\n",
    "    --masks-database=data/masks_base.json \\\n",
    "    --verbose \\\n",
    "    --use-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate landmark estimator by face_alignment library\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init constants\n",
    "\n",
    "batch_size = 32\n",
    "n_jobs = 4\n",
    "epochs = 20\n",
    "image_shape = (112, 112)\n",
    "embedding_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root_dataset_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7dff85aec84f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m generator_train_dataset = PipelineFacesDatasetGenerator(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mroot_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root_dataset_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Init base variables for training\n",
    "\n",
    "generator_train_dataset = PipelineFacesDatasetGenerator(\n",
    "    root_train_dataset_path,\n",
    "    image_shape\n",
    ")\n",
    "\n",
    "generator_test_dataset = PipelineFacesDatasetGenerator(\n",
    "    root_train_dataset_path,\n",
    "    image_shape\n",
    ")\n",
    "\n",
    "train_data = DataLoader(\n",
    "        generator_train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=n_jobs,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    ")\n",
    "\n",
    "model = FaceRecognitionModel(\n",
    "    backbone=Backbone(\n",
    "        backbone=resnet18(pretrained=True),\n",
    "        embedding_size=embedding_size,\n",
    "        input_shape=(3, image_shape[0], image_shape[1])\n",
    "    ),\n",
    "    head=ArcFaceLayer(\n",
    "        embedding_size=embedding_size,\n",
    "        num_classes=generator_train_dataset.num_classes\n",
    "    )\n",
    ")\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
